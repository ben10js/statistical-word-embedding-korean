import json
import numpy as np
import os
from difflib import get_close_matches

# Config
from src.config import CONFIG

# Modules
from src.embedding_utils import nearest_by_word, l2_normalize_embeddings

class MetacogAISearchUI:
    def __init__(self):
        self.main_embeddings = None
        self.main_vocab = None
        self.external_embeddings = None
        self.external_vocab = None

    def load_embeddings(self):
        # Paths from CONFIG
        main_emb_path = os.path.join(CONFIG["embedding_dir"], CONFIG["embedding_file"])
        main_vocab_path = os.path.join(CONFIG["vocab_dir"], CONFIG["vocab_index_file"])
        
        # External paths (assuming same structure or legacy names in root if not in config yet)
        # For now, let's assume they are in data/embeddings as well or use legacy names if they were generated there
        # But main.py saves to data/embeddings.
        # User might have external files in root?
        # Let's try to look in data/embeddings first, then root.
        
        ext_emb_path = os.path.join(CONFIG["embedding_dir"], 'external_embeddings_ppmi_svd.npy')
        ext_vocab_path = os.path.join(CONFIG["vocab_dir"], 'external_vocab_index.json')
        
        # Fallback to root if not found (legacy support)
        if not os.path.exists(ext_emb_path):
             ext_emb_path = 'external_embeddings_ppmi_svd.npy'
        if not os.path.exists(ext_vocab_path):
             ext_vocab_path = 'external_vocab_index.json'

        try:
            print(f"Loading main embeddings from {main_emb_path}...")
            self.main_embeddings = np.load(main_emb_path)
            with open(main_vocab_path, 'r', encoding='utf-8') as f:
                self.main_vocab = json.load(f)
            
            if os.path.exists(ext_emb_path):
                print(f"Loading external embeddings from {ext_emb_path}...")
                self.external_embeddings = np.load(ext_emb_path)
                with open(ext_vocab_path, 'r', encoding='utf-8') as f:
                    self.external_vocab = json.load(f)
                print(f"Loaded main vocab: {len(self.main_vocab)} / external vocab: {len(self.external_vocab)}")
            else:
                print("External embeddings not found. Only main corpus will be used.")
                self.external_vocab = {} # Empty to prevent errors
                
        except Exception as e:
            print(f"Error loading embeddings: {e}")
            return False
        return True

    def interactive_search(self):
        print("\n=== ë©”íƒ€ì¸ì§€ AI ë‹¨ì–´ ê²€ìƒ‰ ì‹œìŠ¤í…œ ===")
        print("ëª…ë ¹ì–´: quit/exit/ì¢…ë£Œ, help, ê²€ìƒ‰ì–´ ì…ë ¥")
        while True:
            try:
                user_input = input("\nê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                if user_input.lower() == 'help':
                    self.show_help()
                    continue
                if not user_input:
                    continue

                res = self.cross_corpus_search_with_feedback(user_input)
                self.display_results(user_input, res)
                if res["mode"] == "cross":
                    self.ask_feedback(user_input, res["found_words"])

            except KeyboardInterrupt:
                print("\nê²€ìƒ‰ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    def cross_corpus_search_with_feedback(self, query_word, topk=10, expand_level=2, max_try_k=50):
        if query_word in self.main_vocab:
            # ë©”ì¸ì½”í¼ìŠ¤ì— ìˆìœ¼ë©´ ê°œì¸ì½”í¼ìŠ¤ ì„ë² ë”©ë§Œ!
            main_emb_norm = l2_normalize_embeddings(self.main_embeddings)
            main_results = nearest_by_word(query_word, main_emb_norm, self.main_vocab, topk=topk)
            return {"mode": "main", "main": main_results}
        else:
            if self.external_embeddings is None:
                 suggestions = get_close_matches(query_word, self.main_vocab.keys(), n=5)
                 return {"mode": "cross", "found_words": [], "suggestions": suggestions}

            ext_emb_norm = l2_normalize_embeddings(self.external_embeddings)
            found_words = []
            def get_candidates(word, k):
                if word in self.external_vocab:
                    return [w for w, _ in nearest_by_word(word, ext_emb_norm, self.external_vocab, topk=k)]
                return []

            # k ì¦ë¶„ í™•ì¥
            for this_k in range(topk, max_try_k+1, topk):
                topk_external = get_candidates(query_word, this_k)
                cross = [w for w in topk_external if w in self.main_vocab]
                if cross:
                    found_words.extend(cross)
                    break

            # 2ì°¨ í™•ì¥
            if not found_words and expand_level > 1:
                first_topk = get_candidates(query_word, topk)
                for w in first_topk:
                    second_topk = get_candidates(w, topk)
                    found_words.extend([ww for ww in second_topk if ww in self.main_vocab])
            found_words = list(set(found_words))

            # ì² ì ì¶”ì²œë„ ê°™ì´ í‘œì‹œ
            suggestions = get_close_matches(query_word, self.external_vocab.keys(), n=5)
            return {"mode": "cross", "found_words": found_words, "suggestions": suggestions}

    def display_results(self, query, res):
        print(f"\n'{query}' ê²€ìƒ‰ ê²°ê³¼:")
        if res.get("mode") == "main":
            print("\nğŸ“– ê°œì¸ ì½”í¼ìŠ¤ì—ì„œ ë°œê²¬:")
            for i, (word, score) in enumerate(res["main"], 1):
                print(f"  {i:2d}. {word:<15} (ìœ ì‚¬ë„: {score:.4f})")
        elif res.get("mode") == "cross":
            if res.get("found_words"):
                print(f"\nğŸŒ ì™¸ë¶€+ë©”ì¸ ì—°ë™ í›„ë³´ ë‹¨ì–´ (ê°œì¸ ì½”í¼ìŠ¤ì—ë„ ì¡´ì¬):")
                print(", ".join(res["found_words"]))
            else:
                print("âŒ ì™¸ë¶€ ì˜ë¯¸ë§ ê¸°ë°˜ í›„ë³´ë„ ê°œì¸ ë¬¸ì„œì—ëŠ” ì—†ìŠµë‹ˆë‹¤.")
            if res.get("suggestions"):
                print(f"ğŸ’¡ ì² ì ìœ ì‚¬ ì¶”ì²œì–´: {', '.join(res['suggestions'])}")

    def ask_feedback(self, query, found_words):
        if not found_words: return
        print(f"\nğŸ’¬ {query}ì™€ ì£¼ê´€ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´ë¥¼ ì•„ë˜ í›„ë³´ ì¤‘ì—ì„œ ê³¨ë¼ì£¼ì„¸ìš”:")
        for i, w in enumerate(found_words, 1):
            print(f"  {i:2d}. {w}")
        print("ì…ë ¥: ë²ˆí˜¸ ë˜ëŠ” ë‹¨ì–´ (ìŠ¤í‚µí•˜ë ¤ë©´ Enter)")
        choice = input("ì„ íƒ: ").strip()
        if choice.isdigit():
            idx = int(choice)
            if 1 <= idx <= len(found_words):
                print(f"â­ï¸ '{query}'ì™€ ì£¼ê´€ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´: {found_words[idx-1]}")
        elif choice in found_words:
            print(f"â­ï¸ '{query}'ì™€ ì£¼ê´€ì ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´: {choice}")
        else:
            print("í”¼ë“œë°±ì´ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    def show_help(self):
        print("\n=== ë„ì›€ë§ ===")
        print("ì´ ì‹œìŠ¤í…œì€ ê°œì¸ ë¬¸ì„œ/ì™¸ë¶€ ì§€ì‹ ì˜ë¯¸ ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜ìœ¼ë¡œ")
        print("ì…ë ¥í•œ ë‹¨ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ê¹Œìš´ ë‹¨ì–´ë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.")
        print("ê°œë³„ ì½”í¼ìŠ¤ ë˜ëŠ” ì™¸ë¶€â†’ê°œì¸ êµì§‘í•© ê¸°ë°˜ ì¶”ì²œê³¼ ì£¼ê´€ì  í”¼ë“œë°±ì„ ì§€ì›í•©ë‹ˆë‹¤.")

# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    search_engine = MetacogAISearchUI()
    if search_engine.load_embeddings():
        search_engine.interactive_search()

