{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 위치: C://external_corpus\\cleaned_md_corpus.jsonl\n"
     ]
    }
   ],
   "source": [
    "# 품사 없는 txt 추출 예시\n",
    "import os\n",
    "import json\n",
    "\n",
    "parent_dir = \"C://external_corpus\" \n",
    "target_name = \"cleaned_md_corpus.jsonl\"\n",
    "found = None\n",
    "for root, dirs, files in os.walk(parent_dir):\n",
    "    for fname in files:\n",
    "        if fname == target_name:\n",
    "            found = os.path.join(root, fname)\n",
    "            print(f\"파일 위치: {found}\")\n",
    "\n",
    "if found:\n",
    "    # 이후 처리\n",
    "    with open(found, \"r\", encoding=\"utf-8\") as fin, open(\"verdict4.txt\", \"w\", encoding=\"utf-8\") as fout:\n",
    "        for line in fin:\n",
    "            if line.strip():\n",
    "                obj = json.loads(line)\n",
    "                fout.write(' '.join([w for w, t in obj[\"pos\"]]) + \"\\n\")\n",
    "else:\n",
    "    print(\"cleaned_md_corpus.jsonl 파일을 찾지 못했습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5f2d1",
   "metadata": {},
   "source": [
    "# 2.2 Tokenizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133d30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"verdict3.txt\"):\n",
    "    url = \"\"\n",
    "    file_path = \"verdict3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa37c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"verdict3.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d57c093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364749"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)  # 원본 텍스트 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbff1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_punctuation_spacing(text):\n",
    "    # 구두점 앞의 공백 제거\n",
    "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "    # 괄호 앞뒤 공백 제거\n",
    "    text = re.sub(r'\\s*([\\(\\)\\[\\]])\\s*', r'\\1', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371f91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = normalize_punctuation_spacing(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c3a821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지메일 에 기록 한 본문 및 한글파일 확인\n",
      "제 이상형 은 열정 인 영혼 을 가진 사람 입니다. 제 이상형 은 열정 을 가진 사람 입니다. 현재 모습 이 볼품 없어도 상관없습니다. \n"
     ]
    }
   ],
   "source": [
    "print(raw_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f07718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verdict3.txt 저장 완료: C://Users//User//Documents//metacogai_via_hyperclova//verdict4.txt\n"
     ]
    }
   ],
   "source": [
    "# 저장 경로 지정\n",
    "file_path = \"C://Users//User//Documents//metacogai_via_hyperclova//verdict4.txt\"\n",
    "\n",
    "# 파일로 저장\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(raw_text)\n",
    "\n",
    "print(\"verdict3.txt 저장 완료:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bb6e1",
   "metadata": {},
   "source": [
    "# 2.3 Converting tokens into token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355b43f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(raw_text))\n",
    "vocab_size = len(all_words)  # 고유 토큰 수\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6d14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)} # markdown refinement에 대한 성능확인 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341be9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "                                \n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ecff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = SimpleTokenizerV1(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3cd673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '.': 8, ':': 9, ';': 10, '?': 11, '[': 12, ']': 13, '~': 14, '’': 15, '…': 16, 'ㄱ': 17, 'ㅇ': 18, 'ㅋ': 19, 'ㅎ': 20, '가': 21, '각': 22, '간': 23, '갇': 24, '갈': 25, '갉': 26, '감': 27, '갑': 28, '값': 29, '갔': 30, '강': 31, '갖': 32, '같': 33, '갚': 34, '개': 35, '객': 36, '갤': 37, '갱': 38, '걀': 39, '거': 40, '걱': 41, '건': 42, '걷': 43, '걸': 44, '검': 45, '겁': 46, '것': 47, '겉': 48, '게': 49, '겐': 50, '겔': 51, '겟': 52, '겠': 53, '겨': 54, '격': 55, '겪': 56, '견': 57, '결': 58, '겸': 59, '겹': 60, '겼': 61, '경': 62, '계': 63, '고': 64, '곡': 65, '곤': 66, '곧': 67, '골': 68, '곰': 69, '곱': 70, '곳': 71, '공': 72, '과': 73, '관': 74, '괄': 75, '광': 76, '괜': 77, '괴': 78, '굉': 79, '교': 80, '구': 81, '국': 82, '군': 83, '굳': 84, '굴': 85, '굶': 86, '궁': 87, '궈': 88, '권': 89, '궤': 90, '귀': 91, '귄': 92, '귐': 93, '규': 94, '균': 95, '그': 96, '극': 97, '근': 98, '글': 99, '긁': 100, '금': 101, '급': 102, '긋': 103, '긍': 104, '기': 105, '긴': 106, '길': 107, '김': 108, '깁': 109, '깃': 110, '깅': 111, '깊': 112, '까': 113, '깍': 114, '깐': 115, '깔': 116, '깝': 117, '깥': 118, '깨': 119, '깬': 120, '깰': 121, '꺼': 122, '껍': 123, '께': 124, '껴': 125, '꼈': 126, '꼬': 127, '꼭': 128, '꼴': 129, '꼼': 130, '꼽': 131, '꽃': 132, '꽉': 133, '꽤': 134, '꾸': 135, '꾼': 136, '꿀': 137, '꿇': 138, '꿈': 139, '꿔': 140, '꿨': 141, '꿰': 142, '뀌': 143, '뀐': 144, '뀔': 145, '뀜': 146, '뀝': 147, '끄': 148, '끈': 149, '끊': 150, '끌': 151, '끔': 152, '끗': 153, '끝': 154, '끼': 155, '끽': 156, '낀': 157, '낄': 158, '낌': 159, '낍': 160, '나': 161, '낙': 162, '낚': 163, '난': 164, '날': 165, '남': 166, '납': 167, '낫': 168, '났': 169, '낭': 170, '낮': 171, '낯': 172, '낱': 173, '낳': 174, '내': 175, '낸': 176, '낼': 177, '냄': 178, '냅': 179, '냈': 180, '냉': 181, '냐': 182, '냥': 183, '너': 184, '넌': 185, '널': 186, '넓': 187, '넘': 188, '넛': 189, '넣': 190, '네': 191, '넥': 192, '넷': 193, '녀': 194, '녁': 195, '년': 196, '념': 197, '녔': 198, '녕': 199, '노': 200, '녹': 201, '논': 202, '놀': 203, '놈': 204, '농': 205, '높': 206, '놓': 207, '놔': 208, '놨': 209, '뇌': 210, '뇨': 211, '누': 212, '눅': 213, '눈': 214, '눌': 215, '눔': 216, '눠': 217, '눴': 218, '뉘': 219, '뉜': 220, '뉨': 221, '뉴': 222, '늄': 223, '느': 224, '는': 225, '늘': 226, '늠': 227, '능': 228, '늦': 229, '니': 230, '닉': 231, '닌': 232, '닐': 233, '님': 234, '닙': 235, '닝': 236, '다': 237, '닥': 238, '닦': 239, '단': 240, '닫': 241, '달': 242, '닭': 243, '닮': 244, '담': 245, '답': 246, '닷': 247, '당': 248, '닿': 249, '대': 250, '댁': 251, '댑': 252, '댓': 253, '더': 254, '덕': 255, '던': 256, '덜': 257, '덤': 258, '덥': 259, '덧': 260, '덩': 261, '덫': 262, '덮': 263, '데': 264, '덱': 265, '덴': 266, '델': 267, '뎠': 268, '도': 269, '독': 270, '돈': 271, '돋': 272, '돌': 273, '돕': 274, '동': 275, '돼': 276, '됐': 277, '되': 278, '된': 279, '될': 280, '됨': 281, '됩': 282, '두': 283, '둑': 284, '둔': 285, '둘': 286, '둠': 287, '둡': 288, '둥': 289, '뒤': 290, '뒷': 291, '듀': 292, '듈': 293, '드': 294, '득': 295, '든': 296, '듣': 297, '들': 298, '듦': 299, '듬': 300, '듭': 301, '듯': 302, '등': 303, '디': 304, '딘': 305, '딜': 306, '딤': 307, '딥': 308, '딧': 309, '딩': 310, '딪': 311, '따': 312, '딱': 313, '딴': 314, '딸': 315, '땀': 316, '땄': 317, '땅': 318, '때': 319, '땐': 320, '떠': 321, '떡': 322, '떤': 323, '떨': 324, '떳': 325, '떴': 326, '떻': 327, '떼': 328, '뗄': 329, '뗌': 330, '또': 331, '똑': 332, '뚜': 333, '뚫': 334, '뚱': 335, '뛰': 336, '뜨': 337, '뜬': 338, '뜯': 339, '뜸': 340, '뜻': 341, '띄': 342, '띕': 343, '띤': 344, '띵': 345, '라': 346, '락': 347, '란': 348, '랄': 349, '람': 350, '랍': 351, '랐': 352, '랑': 353, '래': 354, '랙': 355, '랜': 356, '램': 357, '랩': 358, '랫': 359, '랬': 360, '랭': 361, '략': 362, '량': 363, '러': 364, '럭': 365, '런': 366, '럴': 367, '럼': 368, '럽': 369, '렀': 370, '렁': 371, '렇': 372, '레': 373, '렉': 374, '렌': 375, '렐': 376, '렘': 377, '렙': 378, '렛': 379, '려': 380, '력': 381, '련': 382, '렬': 383, '렴': 384, '렵': 385, '렷': 386, '렸': 387, '령': 388, '례': 389, '로': 390, '록': 391, '론': 392, '롤': 393, '롬': 394, '롭': 395, '롯': 396, '롱': 397, '롸': 398, '뢰': 399, '료': 400, '룡': 401, '루': 402, '룬': 403, '룰': 404, '룸': 405, '룹': 406, '뤄': 407, '뤘': 408, '류': 409, '륙': 410, '률': 411, '륨': 412, '륭': 413, '륰': 414, '르': 415, '른': 416, '를': 417, '름': 418, '릅': 419, '릇': 420, '릉': 421, '릎': 422, '릐': 423, '리': 424, '릭': 425, '린': 426, '릴': 427, '림': 428, '립': 429, '릿': 430, '링': 431, '마': 432, '막': 433, '만': 434, '많': 435, '말': 436, '맑': 437, '맘': 438, '맛': 439, '망': 440, '맞': 441, '맡': 442, '맣': 443, '매': 444, '맥': 445, '맨': 446, '맵': 447, '맷': 448, '맹': 449, '맺': 450, '머': 451, '먹': 452, '먼': 453, '멀': 454, '멈': 455, '멋': 456, '멍': 457, '메': 458, '멕': 459, '멘': 460, '멜': 461, '멤': 462, '멧': 463, '며': 464, '멱': 465, '면': 466, '멸': 467, '명': 468, '몇': 469, '모': 470, '목': 471, '몫': 472, '몬': 473, '몰': 474, '몸': 475, '몹': 476, '못': 477, '몽': 478, '묘': 479, '묜': 480, '무': 481, '묵': 482, '묶': 483, '문': 484, '묻': 485, '물': 486, '뭇': 487, '뭉': 488, '뭐': 489, '뭔': 490, '뭘': 491, '뮤': 492, '뮨': 493, '뮬': 494, '뮴': 495, '므': 496, '믈': 497, '미': 498, '믹': 499, '민': 500, '믿': 501, '밀': 502, '밌': 503, '밍': 504, '및': 505, '밑': 506, '바': 507, '박': 508, '밖': 509, '반': 510, '받': 511, '발': 512, '밝': 513, '밟': 514, '밤': 515, '밥': 516, '방': 517, '배': 518, '백': 519, '밴': 520, '밸': 521, '뱀': 522, '뱅': 523, '뱉': 524, '버': 525, '벅': 526, '번': 527, '벌': 528, '범': 529, '법': 530, '벗': 531, '벚': 532, '베': 533, '벡': 534, '벤': 535, '벨': 536, '벳': 537, '벼': 538, '벽': 539, '변': 540, '별': 541, '볍': 542, '병': 543, '볕': 544, '보': 545, '복': 546, '본': 547, '볼': 548, '봄': 549, '봅': 550, '봇': 551, '봉': 552, '봐': 553, '봤': 554, '봬': 555, '뵙': 556, '부': 557, '북': 558, '분': 559, '불': 560, '붉': 561, '붕': 562, '붙': 563, '뷰': 564, '브': 565, '블': 566, '비': 567, '빅': 568, '빈': 569, '빌': 570, '빗': 571, '빙': 572, '빚': 573, '빛': 574, '빠': 575, '빡': 576, '빨': 577, '빴': 578, '빵': 579, '빼': 580, '빽': 581, '뺀': 582, '뺄': 583, '뺏': 584, '뻔': 585, '뻗': 586, '뼈': 587, '뼛': 588, '뽑': 589, '뿌': 590, '뿐': 591, '쁘': 592, '쁜': 593, '쁨': 594, '삐': 595, '사': 596, '삭': 597, '산': 598, '살': 599, '삶': 600, '삼': 601, '삿': 602, '상': 603, '새': 604, '색': 605, '샌': 606, '샐': 607, '샘': 608, '생': 609, '샵': 610, '서': 611, '석': 612, '섞': 613, '선': 614, '설': 615, '섬': 616, '섭': 617, '섯': 618, '섰': 619, '성': 620, '세': 621, '섹': 622, '센': 623, '셀': 624, '셈': 625, '셉': 626, '셋': 627, '셔': 628, '션': 629, '셜': 630, '셨': 631, '셰': 632, '소': 633, '속': 634, '손': 635, '솔': 636, '솜': 637, '솟': 638, '송': 639, '쇄': 640, '쇼': 641, '숄': 642, '숍': 643, '수': 644, '숙': 645, '순': 646, '술': 647, '숨': 648, '숫': 649, '숭': 650, '숲': 651, '쉐': 652, '쉬': 653, '쉽': 654, '슈': 655, '슐': 656, '슘': 657, '스': 658, '슨': 659, '슬': 660, '슴': 661, '습': 662, '슷': 663, '승': 664, '시': 665, '식': 666, '신': 667, '실': 668, '싫': 669, '심': 670, '십': 671, '싱': 672, '싶': 673, '싸': 674, '싹': 675, '싼': 676, '쌀': 677, '쌈': 678, '쌉': 679, '쌍': 680, '쌓': 681, '쌤': 682, '써': 683, '썬': 684, '썸': 685, '썼': 686, '쎄': 687, '쎈': 688, '쏟': 689, '쐐': 690, '쓰': 691, '쓴': 692, '쓸': 693, '씀': 694, '씁': 695, '씌': 696, '씨': 697, '씩': 698, '씬': 699, '씼': 700, '아': 701, '악': 702, '안': 703, '앉': 704, '않': 705, '알': 706, '암': 707, '압': 708, '앗': 709, '았': 710, '앙': 711, '앞': 712, '애': 713, '액': 714, '앤': 715, '앨': 716, '앱': 717, '앵': 718, '야': 719, '약': 720, '얄': 721, '얇': 722, '양': 723, '얘': 724, '어': 725, '억': 726, '언': 727, '얻': 728, '얼': 729, '얽': 730, '엄': 731, '업': 732, '없': 733, '엇': 734, '었': 735, '엉': 736, '에': 737, '엑': 738, '엔': 739, '엘': 740, '엠': 741, '여': 742, '역': 743, '엮': 744, '연': 745, '열': 746, '염': 747, '엿': 748, '였': 749, '영': 750, '옆': 751, '예': 752, '옛': 753, '오': 754, '옥': 755, '온': 756, '올': 757, '옮': 758, '옳': 759, '옴': 760, '옵': 761, '옷': 762, '옹': 763, '와': 764, '왁': 765, '완': 766, '왓': 767, '왔': 768, '왕': 769, '왜': 770, '왠': 771, '외': 772, '요': 773, '욕': 774, '욜': 775, '욥': 776, '용': 777, '우': 778, '욱': 779, '운': 780, '울': 781, '움': 782, '웃': 783, '웅': 784, '워': 785, '웍': 786, '원': 787, '월': 788, '웜': 789, '웠': 790, '웨': 791, '웬': 792, '웰': 793, '웹': 794, '위': 795, '윈': 796, '윌': 797, '윗': 798, '유': 799, '육': 800, '윤': 801, '율': 802, '융': 803, '으': 804, '은': 805, '을': 806, '음': 807, '응': 808, '의': 809, '이': 810, '익': 811, '인': 812, '일': 813, '읽': 814, '잃': 815, '임': 816, '입': 817, '잇': 818, '있': 819, '잉': 820, '잊': 821, '잎': 822, '자': 823, '작': 824, '잔': 825, '잖': 826, '잘': 827, '잠': 828, '잡': 829, '잣': 830, '장': 831, '잦': 832, '재': 833, '쟁': 834, '저': 835, '적': 836, '전': 837, '절': 838, '젊': 839, '점': 840, '접': 841, '정': 842, '제': 843, '젝': 844, '젠': 845, '젤': 846, '져': 847, '졌': 848, '조': 849, '족': 850, '존': 851, '졸': 852, '좀': 853, '좁': 854, '종': 855, '좇': 856, '좋': 857, '좌': 858, '죄': 859, '죠': 860, '주': 861, '죽': 862, '준': 863, '줄': 864, '줌': 865, '줍': 866, '중': 867, '줘': 868, '줬': 869, '즈': 870, '즉': 871, '즌': 872, '즐': 873, '즘': 874, '즙': 875, '증': 876, '지': 877, '직': 878, '진': 879, '질': 880, '짊': 881, '짐': 882, '집': 883, '짓': 884, '징': 885, '짚': 886, '짜': 887, '짝': 888, '짠': 889, '짤': 890, '짧': 891, '짬': 892, '짱': 893, '째': 894, '쨌': 895, '쩌': 896, '쩔': 897, '쩜': 898, '쪼': 899, '쪽': 900, '쫀': 901, '쫄': 902, '쫓': 903, '쭉': 904, '쭤': 905, '찌': 906, '찍': 907, '찝': 908, '차': 909, '착': 910, '찬': 911, '찮': 912, '찰': 913, '참': 914, '창': 915, '찾': 916, '채': 917, '책': 918, '챕': 919, '챙': 920, '챠': 921, '처': 922, '척': 923, '천': 924, '철': 925, '첨': 926, '첫': 927, '청': 928, '체': 929, '쳐': 930, '쳤': 931, '초': 932, '촉': 933, '촌': 934, '총': 935, '최': 936, '추': 937, '축': 938, '춘': 939, '출': 940, '춤': 941, '춥': 942, '충': 943, '춰': 944, '췄': 945, '췌': 946, '취': 947, '츠': 948, '측': 949, '층': 950, '치': 951, '칙': 952, '친': 953, '칠': 954, '침': 955, '칩': 956, '칭': 957, '카': 958, '칸': 959, '칼': 960, '캐': 961, '캔': 962, '캘': 963, '캠': 964, '캡': 965, '커': 966, '컨': 967, '컬': 968, '컴': 969, '컵': 970, '컸': 971, '케': 972, '켐': 973, '켓': 974, '켜': 975, '켰': 976, '코': 977, '콘': 978, '콜': 979, '콤': 980, '콥': 981, '콩': 982, '쾌': 983, '쿄': 984, '쿠': 985, '쿨': 986, '쿼': 987, '퀀': 988, '퀄': 989, '퀏': 990, '퀴': 991, '퀵': 992, '큐': 993, '큘': 994, '크': 995, '큰': 996, '클': 997, '큼': 998, '키': 999, '킥': 1000, '킨': 1001, '킬': 1002, '킴': 1003, '킵': 1004, '킷': 1005, '킹': 1006, '타': 1007, '탁': 1008, '탄': 1009, '탈': 1010, '탐': 1011, '탑': 1012, '탓': 1013, '탔': 1014, '탕': 1015, '태': 1016, '택': 1017, '탠': 1018, '탭': 1019, '탱': 1020, '터': 1021, '턱': 1022, '턴': 1023, '털': 1024, '텃': 1025, '테': 1026, '텍': 1027, '텐': 1028, '텔': 1029, '템': 1030, '텝': 1031, '텟': 1032, '텨': 1033, '토': 1034, '톡': 1035, '톤': 1036, '톨': 1037, '톰': 1038, '톱': 1039, '통': 1040, '퇴': 1041, '투': 1042, '툰': 1043, '툴': 1044, '튀': 1045, '튜': 1046, '튬': 1047, '튭': 1048, '트': 1049, '특': 1050, '튼': 1051, '틀': 1052, '틈': 1053, '티': 1054, '틱': 1055, '틴': 1056, '틸': 1057, '팀': 1058, '팁': 1059, '팅': 1060, '파': 1061, '팍': 1062, '팎': 1063, '판': 1064, '팔': 1065, '팜': 1066, '팟': 1067, '팡': 1068, '팥': 1069, '패': 1070, '팩': 1071, '팬': 1072, '팽': 1073, '퍼': 1074, '펀': 1075, '펌': 1076, '펐': 1077, '페': 1078, '펙': 1079, '펜': 1080, '펠': 1081, '펩': 1082, '펫': 1083, '펭': 1084, '펴': 1085, '편': 1086, '펼': 1087, '평': 1088, '폐': 1089, '포': 1090, '폭': 1091, '폰': 1092, '폴': 1093, '폼': 1094, '퐁': 1095, '표': 1096, '푸': 1097, '푹': 1098, '푼': 1099, '풀': 1100, '품': 1101, '풋': 1102, '풍': 1103, '퓨': 1104, '프': 1105, '픈': 1106, '플': 1107, '픔': 1108, '피': 1109, '픽': 1110, '핀': 1111, '필': 1112, '핍': 1113, '핏': 1114, '핑': 1115, '하': 1116, '학': 1117, '한': 1118, '할': 1119, '함': 1120, '합': 1121, '핫': 1122, '항': 1123, '해': 1124, '핵': 1125, '핸': 1126, '햄': 1127, '햅': 1128, '햇': 1129, '했': 1130, '행': 1131, '햐': 1132, '향': 1133, '허': 1134, '헌': 1135, '헐': 1136, '험': 1137, '헛': 1138, '헤': 1139, '헬': 1140, '헷': 1141, '혀': 1142, '혁': 1143, '현': 1144, '혈': 1145, '혐': 1146, '협': 1147, '혔': 1148, '형': 1149, '혜': 1150, '호': 1151, '혹': 1152, '혼': 1153, '홀': 1154, '홈': 1155, '홉': 1156, '홍': 1157, '화': 1158, '확': 1159, '환': 1160, '활': 1161, '황': 1162, '회': 1163, '획': 1164, '횡': 1165, '효': 1166, '후': 1167, '훈': 1168, '훌': 1169, '훑': 1170, '훨': 1171, '훼': 1172, '휘': 1173, '휩': 1174, '휴': 1175, '흉': 1176, '흐': 1177, '흑': 1178, '흔': 1179, '흘': 1180, '흠': 1181, '흡': 1182, '흥': 1183, '흩': 1184, '희': 1185, '흰': 1186, '히': 1187, '힌': 1188, '힐': 1189, '힘': 1190, '힙': 1191}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe827ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60cd64c",
   "metadata": {},
   "source": [
    "# 2.4 Adding special context tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "116751da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Hello, I love fully passionate person.\"\n",
    "# tokenizer.encode(text)  # 오류 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19434c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_tokens = sorted(list(set(raw_text)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e70f3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)  # Special tokens added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccafc879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (';', 10)\n",
      "1 ('?', 11)\n",
      "2 ('[', 12)\n",
      "3 (']', 13)\n",
      "4 ('~', 14)\n",
      "5 ('’', 15)\n",
      "6 ('…', 16)\n",
      "7 ('ㄱ', 17)\n",
      "8 ('ㅇ', 18)\n",
      "9 ('ㅋ', 19)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[10:20]):\n",
    "    print(i, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d8f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = { i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int \n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|> <|unk|> <|unk|> <|unk|> <|unk|> <|unk|>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "tokenizer.encode(text)\n",
    "tokenizer.decode(tokenizer.encode(text))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b409435",
   "metadata": {},
   "source": [
    "# 2.5 Byte pair encoding (tiktoken - nanoGPT - 한글 customize)\n",
    "## 한국어 특성상 bpe를 안쓰는 게 좋음. OKT로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88412bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35438d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import sentencepiece as spm\n",
    "\n",
    "# 1. 학습\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input='verdict4.txt',\n",
    "    model_prefix='mymeta_tokenizer4',\n",
    "    vocab_size=1192,\n",
    "    model_type='unigram', # 'bpe', 'word', 'char'도 선택 가능\n",
    "    character_coverage=1.0, # 한글 특화는 1.0 추천\n",
    "    pad_id=0,         # <pad> 토큰이 0번 인덱스에 오도록 명시\n",
    "    unk_id=1,         # <unk> 1번\n",
    "    bos_id=2,         # <s> 2번\n",
    "    eos_id=3,         # </s> 3번 (여기서 <eos>와 </s>는 용도 구분)\n",
    "    user_defined_symbols=['<EOS>', '<PARA_END>','<meta>', '<user>', '<feedback>'] # 사업 특화 토큰 추가 가능, 사용자가 정의한 문장끝과 문단끝 정보 포함\n",
    ")\n",
    "\n",
    "# 2. 적용\n",
    "sp = spm.SentencePieceProcessor(model_file='mymeta_tokenizer4.model')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d1f5e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 6, 1, 7, 8, 11]\n",
      "나 는 밥 을 먹었다 .\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "class SimpleKoreanTokenizer:\n",
    "    def __init__(self):\n",
    "        self.okt = Okt()\n",
    "        self.vocab = {}\n",
    "        self.inv_vocab = {}\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        # 형태소 단위 토큰화 (koNLPy Okt)\n",
    "        tokens = self.okt.morphs(text)\n",
    "        return tokens\n",
    "    \n",
    "    def build_vocab(self, corpus):\n",
    "        # corpus: 텍스트 리스트\n",
    "        all_tokens = set()\n",
    "        for sent in corpus:\n",
    "            tokens = self.tokenize(sent)\n",
    "            all_tokens.update(tokens)\n",
    "        self.vocab = {token: idx for idx, token in enumerate(all_tokens)}\n",
    "        self.inv_vocab = {idx: token for token, idx in self.vocab.items()}\n",
    "        \n",
    "    def encode(self, text):\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.vocab[token] for token in tokens if token in self.vocab]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return ' '.join([self.inv_vocab[i] for i in ids if i in self.inv_vocab])\n",
    "\n",
    "# 예시 사용법\n",
    "corpus = [\"나는 밥을 먹었다.\", \"한국어 토크나이저를 테스트합니다.\"]\n",
    "tokenizer = SimpleKoreanTokenizer()\n",
    "tokenizer.build_vocab(corpus)\n",
    "\n",
    "encoded = tokenizer.encode(\"나는 밥을 먹었다.\")\n",
    "print(encoded)  # vocab ID list\n",
    "print(tokenizer.decode(encoded))  # 형태소 단위로 복원된 문장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ddd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 6, 7, 11]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"나는 열정 가득한 사람을 좋아한다. <EOS> 그리고 그게 너다.<EO><PARA_END>\")\n",
    "print(tokens) \n",
    "# 영어/한글 둘 다 실제 코퍼스(\"verdict2.txt\" 등)에서 많이 나오는 말일수록 컷팅 없이 하나의 서브워드가 되고, 희귀한 부분이나 복합어, 추출이 어려운 부분은 더 잘게 쪼개짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e143fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본: 나는 열정 가득한 사람을 좋아한다. <EOS> 그리고 그게 너다.<EO><PARA_END>\n",
      "id 리스트: [4, 12, 19, 5, 17, 13, 18, 3, 8, 20, 2, 16, 1, 7, 15, 11, 14, 6, 0, 10, 9, 2]\n",
      "토큰 리스트: ['나', '는', '열정', '가득한', '사람', '을', '좋아한다', '.', '<', 'EOS', '>', '그리고', '그게', '너', '다', '.<', 'EO', '><', 'PARA', '_', 'END', '>']\n",
      "decode(ids): 나 는 열정 가득한 사람 을 좋아한다 . < EOS > 그리고 그게 너 다 .< EO >< PARA _ END >\n",
      "decode(tokens): 나 는 열정 가득한 사람 을 좋아한다 . < EOS > 그리고 그게 너 다 .< EO >< PARA _ END >\n"
     ]
    }
   ],
   "source": [
    "# 실험 예시\n",
    "corpus = [\"나는 열정 가득한 사람을 좋아한다. <EOS> 그리고 그게 너다.<EO><PARA_END>\"]\n",
    "tokenizer = SimpleKoreanTokenizer()\n",
    "tokenizer.build_vocab(corpus)\n",
    "\n",
    "text = \"나는 열정 가득한 사람을 좋아한다. <EOS> 그리고 그게 너다.<EO><PARA_END>\"\n",
    "ids = tokenizer.encode(text)\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "decoded_text_from_ids = tokenizer.decode(ids)\n",
    "decoded_text_from_tokens = ' '.join(tokens)\n",
    "\n",
    "print(\"원본:\", text)\n",
    "print(\"id 리스트:\", ids)\n",
    "print(\"토큰 리스트:\", tokens)\n",
    "print(\"decode(ids):\", decoded_text_from_ids)\n",
    "print(\"decode(tokens):\", decoded_text_from_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc70fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11526"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(raw_text)  # OKT\n",
    "len(ids)  # 토큰 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d9d002",
   "metadata": {},
   "source": [
    "# 2.6 Data sampling with a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "099af32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [7, 13, 232, 87, 7, 159, 7, 11, 155, 7, 17, 7, 99, 39, 7, 152, 7, 17, 341, 162, 87, 7, 1025, 33, 7, 48, 7, 15, 36, 110, 7, 29] -> Target ID: 7\n",
      "Input IDs: [13, 232, 87, 7, 159, 7, 11, 155, 7, 17, 7, 99, 39, 7, 152, 7, 17, 341, 162, 87, 7, 1025, 33, 7, 48, 7, 15, 36, 110, 7, 29, 7] -> Target ID: 184\n",
      "Input IDs: [232, 87, 7, 159, 7, 11, 155, 7, 17, 7, 99, 39, 7, 152, 7, 17, 341, 162, 87, 7, 1025, 33, 7, 48, 7, 15, 36, 110, 7, 29, 7, 184] -> Target ID: 32\n"
     ]
    }
   ],
   "source": [
    "context_size = 32  # 원하는 context window 길이 값으로 설정\n",
    "\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(len(ids) - context_size):\n",
    "    chunk = ids[i:i+context_size]\n",
    "    next_token = ids[i+context_size]\n",
    "    inputs.append(chunk)\n",
    "    targets.append(next_token)\n",
    "    if i < 3:  # 처음 3개만 출력해보기\n",
    "        print(f\"Input IDs: {chunk} -> Target ID: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81475e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da87d9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c58114cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu121'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4dc04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(inputs, dtype=torch.long)\n",
    "targets = torch.tensor(targets, dtype=torch.long)\n",
    "# PyTorch 텐서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3629082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class GPTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "train_dataset = GPTDataset(inputs, targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# DataLoader/배치화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c4cca",
   "metadata": {},
   "source": [
    "# 2.7 Creating token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbf13260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32])\n"
     ]
    }
   ],
   "source": [
    "inputs_batch, targets_batch = next(iter(train_loader))  # DataLoader에서 배치 추출\n",
    "print(inputs_batch.shape)  # (batch_size, context_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "092a1fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 6000   # 너의 커스텀 토크나이저 vocab 크기(예: sp.get_piece_size())\n",
    "context_len = inputs_batch.shape[1]\n",
    "embed_dim = 256 \n",
    "\n",
    "# 토큰 임베딩\n",
    "token_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "tok_vecs = token_embed(inputs_batch)  # (batch_size, context_len, embed_dim)\n",
    "\n",
    "# 포지션 임베딩\n",
    "pos_embed = nn.Embedding(context_len, embed_dim)\n",
    "positions = torch.arange(context_len).unsqueeze(0).expand(inputs_batch.shape[0], context_len)\n",
    "pos_vecs = pos_embed(positions)       # (batch_size, context_len, embed_dim)\n",
    "\n",
    "# 합산 (Transformer에 입력할 벡터)\n",
    "input_embeds = tok_vecs + pos_vecs\n",
    "print(input_embeds.shape)             # (batch_size, context_len, embed_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13325474",
   "metadata": {},
   "source": [
    "# 3. Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9745a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "batch_size, seq_len, embed_dim = input_embeds.shape  # 예: [64, 32, 256]\n",
    "\n",
    "# Q, K, V projection\n",
    "W_q = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_k = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "W_v = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "\n",
    "Q = W_q(input_embeds)  # (batch_size, seq_len, embed_dim)\n",
    "K = W_k(input_embeds)  # (batch_size, seq_len, embed_dim)\n",
    "V = W_v(input_embeds)  # (batch_size, seq_len, embed_dim)\n",
    "\n",
    "# Attention Score\n",
    "scores = torch.matmul(Q, K.transpose(-2, -1)) / (embed_dim ** 0.5)  # (batch_size, seq_len, seq_len)\n",
    "attn_weights = F.softmax(scores, dim=-1)  # (batch_size, seq_len, seq_len)\n",
    "attn_output = torch.matmul(attn_weights, V)  # (batch_size, seq_len, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2cccd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape  # (batch_size, seq_len, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde741d",
   "metadata": {},
   "source": [
    "# 3.6 multi-head attention (의사결정 분기점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7b429d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be578930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores (마스킹 전): tensor([-0.2258, -0.5215,  0.3114,  0.6646,  0.8169,  0.4618, -0.7205,  0.3842,\n",
      "         0.4135,  0.0622,  0.1105,  0.1578,  0.2446, -0.6787,  0.9153, -0.1507,\n",
      "         0.4694, -1.0594,  0.6054,  0.0505,  0.4967,  0.6069,  0.1356,  0.8830,\n",
      "        -1.6526, -0.0515, -0.3932,  1.0041,  0.1669,  0.2680, -0.3903,  0.7217],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "attn_weights: tensor([0.0189, 0.0141, 0.0324, 0.0461, 0.0537, 0.0376, 0.0115, 0.0348, 0.0359,\n",
      "        0.0252, 0.0265, 0.0278, 0.0303, 0.0120, 0.0593, 0.0204, 0.0379, 0.0082,\n",
      "        0.0435, 0.0250, 0.0390, 0.0435, 0.0272, 0.0574, 0.0045, 0.0225, 0.0160,\n",
      "        0.0648, 0.0280, 0.0310, 0.0161, 0.0488], grad_fn=<SelectBackward0>)\n",
      "torch.Size([64, 32, 256])\n",
      "Output tensor([[[-0.8003, -0.1837,  0.1214,  ...,  0.6298, -0.6008, -0.5513],\n",
      "         [-0.4647, -0.0607,  0.2884,  ...,  0.4465, -0.4608, -0.4436],\n",
      "         [-0.5224, -0.2076,  0.2428,  ...,  0.2651, -0.3999, -0.3629],\n",
      "         ...,\n",
      "         [-0.7787, -0.0545,  0.1645,  ...,  0.8119, -0.4285, -0.4623],\n",
      "         [-0.6681, -0.2859,  0.2083,  ...,  0.4121, -0.3990, -0.3190],\n",
      "         [-0.6118, -0.0769,  0.2010,  ...,  0.4908, -0.3892, -0.3445]],\n",
      "\n",
      "        [[-0.4764, -0.1002, -0.0359,  ...,  0.5488, -0.2223, -0.4360],\n",
      "         [-0.2897, -0.0886,  0.3270,  ...,  0.3916, -0.2624, -0.4885],\n",
      "         [-0.3927, -0.1307, -0.0305,  ...,  0.3207, -0.2499, -0.4176],\n",
      "         ...,\n",
      "         [-0.5075, -0.1313,  0.0850,  ...,  0.5098, -0.1967, -0.4197],\n",
      "         [-0.1795,  0.0730, -0.0458,  ...,  0.1892, -0.0313, -0.2913],\n",
      "         [-0.3871,  0.0097, -0.0746,  ...,  0.4052, -0.1557, -0.5471]],\n",
      "\n",
      "        [[-0.6975, -0.0680, -0.2947,  ...,  0.4593, -0.3422, -0.3964],\n",
      "         [-0.4427,  0.0686, -0.0272,  ...,  0.3832, -0.0840, -0.1363],\n",
      "         [-0.5323,  0.0459, -0.1278,  ...,  0.3923, -0.2016, -0.3283],\n",
      "         ...,\n",
      "         [-0.5777,  0.0049, -0.0662,  ...,  0.5533, -0.2160, -0.3218],\n",
      "         [-0.4616,  0.3707, -0.4418,  ...,  0.0764,  0.1441, -0.1053],\n",
      "         [-0.5200,  0.1781, -0.2095,  ...,  0.5463, -0.0923, -0.1823]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6712, -0.1326,  0.1413,  ...,  0.7105, -0.4515, -0.4424],\n",
      "         [-0.4991, -0.2824,  0.1395,  ...,  0.5680, -0.3308, -0.7023],\n",
      "         [-0.6399, -0.1547, -0.0031,  ...,  0.4375, -0.5319, -0.4984],\n",
      "         ...,\n",
      "         [-0.6432, -0.1389,  0.0935,  ...,  0.6205, -0.4993, -0.3827],\n",
      "         [-0.4058, -0.2035, -0.0640,  ...,  0.1258, -0.3596, -0.5048],\n",
      "         [-0.3503, -0.0171, -0.0358,  ...,  0.4910, -0.1058, -0.0080]],\n",
      "\n",
      "        [[-1.1492, -0.0582,  0.0790,  ...,  0.6217, -0.7226, -0.8253],\n",
      "         [-0.6080, -0.0543,  0.0851,  ...,  0.6011, -0.4069, -0.5105],\n",
      "         [-0.2761,  0.0442,  0.2447,  ...,  0.4065, -0.1930, -0.2933],\n",
      "         ...,\n",
      "         [-0.7874,  0.0302, -0.0170,  ...,  0.6645, -0.4572, -0.5288],\n",
      "         [-0.5343,  0.0866, -0.0862,  ...,  0.3193, -0.2898, -0.4433],\n",
      "         [-0.5784,  0.0205,  0.0406,  ...,  0.5322, -0.3687, -0.4246]],\n",
      "\n",
      "        [[-0.7701, -0.2480, -0.0547,  ...,  0.5102, -0.3539, -0.4488],\n",
      "         [-0.7861, -0.2226, -0.0458,  ...,  0.6135, -0.4162, -0.4697],\n",
      "         [-0.4666, -0.2441, -0.0629,  ...,  0.1924, -0.3328, -0.1158],\n",
      "         ...,\n",
      "         [-0.6415, -0.1569, -0.0967,  ...,  0.4419, -0.3780, -0.3076],\n",
      "         [-0.6177, -0.1222, -0.1603,  ...,  0.2819, -0.3808, -0.2887],\n",
      "         [-0.6706, -0.1207, -0.0160,  ...,  0.4573, -0.3138, -0.2882]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Casual Mask 구현\n",
    "import torch\n",
    "\n",
    "# scores shape: (batch, num_heads, seq_len, seq_len)\n",
    "\n",
    "seq_len = scores.size(-1)\n",
    "# 1. 마스크 행렬 생성 (상삼각, i < j 위치에 -inf 적용)\n",
    "mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool() # upper triangular\n",
    "\n",
    "# 2. mask 확장 (batch, num_heads 포함)\n",
    "mask = mask.unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len, seq_len)\n",
    "mask = mask.expand(scores.size(0), scores.size(1), seq_len, seq_len)  # (batch, num_heads, seq_len, seq_len)\n",
    "print(\"scores (마스킹 전):\", scores[0,0])         # 예시 첫 batch, 첫 head 출력\n",
    "\n",
    "# -inf 등장 여부 및 미래 영역 차단 확인\n",
    "\n",
    "attn_weights = torch.softmax(scores, dim=-1)\n",
    "print(\"attn_weights:\", attn_weights[0,0])  # 예시 첫 batch, 첫 head 출력\n",
    "attn_output = torch.matmul(attn_weights, V)\n",
    "print(attn_output.shape)  # (batch_size, seq_len, embed_dim)\n",
    "print(\"Output\", attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52393daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def multi_head_attention(Q, K, V, num_heads, mask_future=True, dropout_p=0.1):\n",
    "    # Q, K, V shape: (batch, seq_len, emb_dim)\n",
    "    batch_size, seq_len, emb_dim = Q.size()\n",
    "    head_dim = emb_dim // num_heads\n",
    "\n",
    "    # 1. 분할: head별로 나누기\n",
    "    def split_heads(x):\n",
    "        # (batch, seq_len, emb_dim) -> (batch, num_heads, seq_len, head_dim)\n",
    "        return x.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
    "\n",
    "    Qh = split_heads(Q)\n",
    "    Kh = split_heads(K)\n",
    "    Vh = split_heads(V)\n",
    "\n",
    "    # 2. 스케일 점수 계산\n",
    "    scores = torch.matmul(Qh, Kh.transpose(-2, -1)) / torch.sqrt(torch.tensor(head_dim, dtype=torch.float32, device=Q.device))\n",
    "\n",
    "    # 3. causal mask 적용 (상삼각)\n",
    "    if mask_future:\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=Q.device), diagonal=1).bool()\n",
    "        mask = mask.unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len, seq_len)\n",
    "        mask = mask.expand(batch_size, num_heads, seq_len, seq_len)\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "    # 4. softmax, dropout\n",
    "    attn_weights = F.softmax(scores, dim=-1)\n",
    "    attn_weights = F.dropout(attn_weights, p=dropout_p, training=True)\n",
    "\n",
    "    # 5. 어텐션 값 연산\n",
    "    attn_output = torch.matmul(attn_weights, Vh)  # (batch, num_heads, seq_len, head_dim)\n",
    "\n",
    "    # 6. head 합치기\n",
    "    attn_output = attn_output.transpose(1, 2).reshape(batch_size, seq_len, emb_dim)\n",
    "\n",
    "    # 7. 필요시 attn_weights 리턴\n",
    "    return attn_output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ac0fed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈화\n",
    "class MultiHeadAttentionWrapper(torch.nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_p = dropout_p\n",
    "        # Q, K, V projection: Linear layers, emb_dim → emb_dim\n",
    "        self.W_q = torch.nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_k = torch.nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_v = torch.nn.Linear(emb_dim, emb_dim)\n",
    "        self.W_o = torch.nn.Linear(emb_dim, emb_dim)\n",
    "    def forward(self, x):\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "        attn_output, attn_weights = multi_head_attention(\n",
    "            Q, K, V,\n",
    "            num_heads=self.num_heads,\n",
    "            mask_future=True,\n",
    "            dropout_p=self.dropout_p\n",
    "        )\n",
    "        return self.W_o(attn_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5291ed21",
   "metadata": {},
   "source": [
    "# 4. 직접 모델 만들기(의사결정 항시개입)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0f7e0",
   "metadata": {},
   "source": [
    "# 4.1 Coding an LLM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54de8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multihead_attention import MultiHeadAttention  # 본인 구현/import\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, unbiased=False, keepdim=True)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"])\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttentionWrapper(\n",
    "            emb_dim=cfg[\"emb_dim\"],\n",
    "        num_heads=cfg[\"n_heads\"],\n",
    "        dropout_p=cfg[\"drop_rate\"]\n",
    "    )\n",
    "\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "    def forward(self, x):\n",
    "        # Residual + Dropout + Attention\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        # Residual + Dropout + FeedForward\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "        )\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d380dd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   7,   40,    8,    7,  184,   32,    7,   20,  250,   17,    7,   16,\n",
      "          504,   45,    7, 1026,   35,   17,   12,    1,    7,    5,    7,  200,\n",
      "           18,    9,    7,  200,   27,    7,  287,   12,    1],\n",
      "        [   7,  124,   87,    7,   19,   79,   38,    8,    7,  108,   47,   29,\n",
      "            7,  835,  258,   77,    1,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
      "[[7, 40, 8, 7, 184, 32, 7, 20, 250, 17, 7, 16, 504, 45, 7, 1026, 35, 17, 12, 1, 7, 5, 7, 200, 18, 9, 7, 200, 27, 7, 287, 12, 1], [7, 124, 87, 7, 19, 79, 38, 8, 7, 108, 47, 29, 7, 835, 258, 77, 1]]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저, 패딩기능 추가하여 수정\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "\n",
    "class MetaTokenizer:\n",
    "    def __init__(self, model_file, pad_id=0):\n",
    "        self.sp = spm.SentencePieceProcessor(model_file='mymeta_tokenizer.model') # 내 모델 넣기\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.sp.encode(text)\n",
    "\n",
    "    def batch_encode(self, texts, padding=True):\n",
    "        batch_ids = [self.sp.encode(t) for t in texts]\n",
    "        if not padding:\n",
    "            # 그냥 리스트(List[List[int]]) 반환\n",
    "            return batch_ids\n",
    "        max_len = max(len(ids) for ids in batch_ids)\n",
    "        batch_padded = [\n",
    "            ids + [self.pad_id]*(max_len - len(ids)) for ids in batch_ids\n",
    "        ]\n",
    "        return torch.tensor(batch_padded, dtype=torch.long)\n",
    "\n",
    "    def batch_encode_with_mask(self, texts, padding=True):\n",
    "        batch_ids = [self.sp.encode(t) for t in texts]\n",
    "        if not padding:\n",
    "            return batch_ids, None\n",
    "        max_len = max(len(ids) for ids in batch_ids)\n",
    "        batch_padded, masks = [], []\n",
    "        for ids in batch_ids:\n",
    "            pad_length = max_len - len(ids)\n",
    "            batch_padded.append(ids + [self.pad_id]*pad_length)\n",
    "            masks.append([1]*len(ids) + [0]*pad_length)\n",
    "        batch_tensor = torch.tensor(batch_padded, dtype=torch.long)\n",
    "        mask_tensor = torch.tensor(masks, dtype=torch.long)\n",
    "        return batch_tensor, mask_tensor\n",
    "\n",
    "# 사용 예시\n",
    "tokenizer = MetaTokenizer('mymeta_tokenizer.model', pad_id=0)\n",
    "texts = [\"나는 열정 가득한 사람을 좋아한다. <user> 그리고 그게 너다.\", \"매일 도전하는 당신은 멋져요.\"]\n",
    "batch = tokenizer.batch_encode(texts, padding=True)      # 텐서, 자동 패딩\n",
    "batch_nopad = tokenizer.batch_encode(texts, padding=False) # 리스트, 패딩 없음\n",
    "\n",
    "print(batch)\n",
    "print(batch_nopad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68c1db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[   7,   40,    8,    7,  184,   32,   15,    7,   20,  250,   17,\n",
      "             7,   16,  504,   45,    7, 1026,   35,   17,   12,    1],\n",
      "         [   7,    1,    7,    1,    7,    1,    7,    1,    0,    0,    0,\n",
      "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11604\\205133308.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch.append(torch.tensor(tokenizer.batch_encode([txt1, txt2], padding=True)))\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer = MetaTokenizer('mymeta_tokenizer.model', pad_id=0)\n",
    "batch = []\n",
    "\n",
    "txt1 = \"나는 열정이 가득한 사람을 좋아한다.\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.batch_encode([txt1, txt2], padding=True)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dae2243f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 33, 6000])\n",
      "torch.Size([2, 33, 6000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 네가 정의한 config 예시\n",
    "MY_CONFIG = {\n",
    "    \"vocab_size\": 6000,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 256,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "\n",
    "model = GPTModel(MY_CONFIG)\n",
    "\n",
    "texts = [\"나는 열정 가득한 사람을 좋아한다. <user> 그리고 그게 너다.\", \"매일 도전하는 당신은 멋져요.\"]\n",
    "batch = tokenizer.batch_encode(texts, padding=True)     # (batch_size, seq_len)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)    # (batch_size, seq_len, vocab_size)\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d200f52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 6,297,088\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36fa8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([6000, 256])\n",
      "Output layer shape: torch.Size([6000, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "14ddd4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 4,761,088\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 =  total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71c73a",
   "metadata": {},
   "source": [
    "## 히트맵 구현 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb796b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e1acef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import seaborn as sns\n",
    "\n",
    "# Windows 기준 나눔고딕/NanumGothic이 있을 경우\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/malgun.ttf\"         # or malgunbd.ttf\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "\n",
    "def visualize_attention(attn_weights, tokens, head_idx=0, savefile=None):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    sns.heatmap(attn_weights[0, head_idx].detach().cpu().numpy(),\n",
    "                xticklabels=tokens, yticklabels=tokens, annot=False, cmap=\"viridis\")\n",
    "    plt.title(f\"Head {head_idx} Attention Heatmap\")\n",
    "    plt.xlabel('Key')\n",
    "    plt.ylabel('Query')\n",
    "    plt.tight_layout()\n",
    "    if savefile:\n",
    "        plt.savefig(savefile)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ef5d334",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m head_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 시각화할 헤드 인덱스\u001b[39;00m\n\u001b[0;32m     10\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens)\n\u001b[1;32m---> 11\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mattn_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 히트맵용 정사각 서브매트릭스\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     14\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(weights\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), xticklabels\u001b[38;5;241m=\u001b[39mtokens, yticklabels\u001b[38;5;241m=\u001b[39mtokens,\n\u001b[0;32m     15\u001b[0m             cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 변수들 준비\n",
    "# tokens: 한글 토큰 리스트 (ex. ['나는', '열정있는', '사람을', ...])\n",
    "# attn_weights: shape (batch_size, num_heads, seq_len, seq_len)\n",
    "# head_idx: 시각화할 head 번호. 예시로 0번 사용.\n",
    "\n",
    "head_idx = 1  # 시각화할 헤드 인덱스\n",
    "n = len(tokens)\n",
    "weights = attn_weights[0, head_idx, :n, :n]  # 히트맵용 정사각 서브매트릭스\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(weights.cpu().detach().numpy(), xticklabels=tokens, yticklabels=tokens,\n",
    "            cmap='viridis', vmin=0, vmax=1, annot=True, fmt=\".2f\")\n",
    "plt.title(f\"Head {head_idx} Attention Heatmap\")\n",
    "plt.xlabel(\"Key\")\n",
    "plt.ylabel(\"Query\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f1ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeds = embedding_layer(tokens)  # 예시: 임베딩레이어 혹은 transformer encoder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
